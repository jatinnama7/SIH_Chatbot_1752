{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c710d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from fuzzywuzzy import fuzz\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./fine-tuned-gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./fine-tuned-gpt2\")\n",
    "\n",
    "# Add padding token if not already present\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "\n",
    "# Load intents from JSON file\n",
    "with open('intents.json', 'r') as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Function to match user input with patterns and return an appropriate response using fuzzy matching\n",
    "def get_intent_response(message):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    threshold = 70  # Define a threshold for fuzzy matching\n",
    "\n",
    "    for intent in intents['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            # Use fuzzy matching to find the best match\n",
    "            score = fuzz.ratio(pattern.lower(), message.lower())\n",
    "            if score > best_score and score > threshold:\n",
    "                best_score = score\n",
    "                best_match = intent\n",
    "\n",
    "    # Return a random response from the best matching intent, if found\n",
    "    if best_match:\n",
    "        return random.choice(best_match['responses'])\n",
    "    return None\n",
    "\n",
    "# Function to generate a response using the fine-tuned model with enhanced logic\n",
    "def generate_response(input_text):\n",
    "    # Adjust input for more context-aware responses\n",
    "    input_text = f\"Question: {input_text} Answer:\"  # Adding explicit guidance for the model\n",
    "\n",
    "    # Generate response with adjusted settings to reduce repetition\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding='max_length', max_length=150)\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,  # More focused response generation\n",
    "        top_p=0.9,        # Narrower range for better relevance\n",
    "        top_k=50,         # Lower k for better control\n",
    "        repetition_penalty=1.15,  # To avoid repetition in responses\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Post-process to filter out irrelevant or off-topic responses\n",
    "    response = response.replace(\"User:\", \"\").replace(\"Bot:\", \"\").strip()\n",
    "    if len(response.split()) < 5 or \"Question:\" in response or \"Answer:\" in response:\n",
    "        response = \"I'm not sure how to answer that. Could you please clarify your question?\"\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "print(\"GO! Bot is running...\")\n",
    "\n",
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    # First try to get a response from the intents JSON\n",
    "    intent_response = get_intent_response(message)\n",
    "    if intent_response:\n",
    "        res = intent_response\n",
    "    else:\n",
    "        # Fallback to the model-generated response if no intent matches\n",
    "        res = generate_response(message)\n",
    "    \n",
    "    print(f\"Bot: {res}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
